{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"source":["# Objective"]},{"cell_type":"markdown","metadata":{},"source":["The aim of this project is to build a basic chatbot using Hugging Face lab. We would be utilizing a pre-trained model called 'facebook/blenderbot-400M-distill'."]},{"cell_type":"markdown","metadata":{},"source":["# Introduction"]},{"cell_type":"markdown","metadata":{},"source":["## Operation of a Chatbot\n","A chatbot is like a digital assistant that uses a combination of advanced computer programs called transformers and language models (LLMs) to communicate with users through text. The transformers act as the chatbot's \"brain,\" while the LLMs are its \"language understanding\" component.\n","\n","When you input a message, the transformer helps the chatbot break it down into smaller pieces called tokens, which are easier for the chatbot to process. These tokens are then passed to the LLM, which has been trained on a vast amount of text data to understand language patterns and meanings.\n","\n","Based on its understanding of the message, the LLM generates a response that makes sense in the context of the conversation. The transformer then converts this response into a format that can be easily delivered back to you.\n","\n","This process continues iteratively as the conversation unfolds. Each new input message is processed, understood by the LLM, and used to generate a relevant response.\n","\n","Essentially, the chatbot leverages the language model's knowledge of human conversations and patterns to generate meaningful responses. The transformer aids in handling the technical aspects of input/output, allowing the language model to focus on understanding and generating language in a coherent and contextually appropriate manner."]},{"attachments":{"dc92e47b-564f-42e4-980e-793e9ba1a419.png":{"image/png":"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"}},"cell_type":"markdown","metadata":{},"source":["   ![Chattbot.png](attachment:dc92e47b-564f-42e4-980e-793e9ba1a419.png)"]},{"cell_type":"markdown","metadata":{},"source":["# Installing Requirements"]},{"cell_type":"markdown","metadata":{},"source":["We will be using the 'transformers' Python library from Hugging Face Lab, which is an open-source natural language processing (NLP) toolkit with many useful features."]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2023-07-03T14:06:35.651539Z","iopub.status.busy":"2023-07-03T14:06:35.650909Z","iopub.status.idle":"2023-07-03T14:06:49.531344Z","shell.execute_reply":"2023-07-03T14:06:49.529539Z","shell.execute_reply.started":"2023-07-03T14:06:35.651484Z"},"trusted":true},"source":["pip install transformers"]},{"cell_type":"markdown","metadata":{},"source":["# Import Required Tools from the Transformers Library"]},{"cell_type":"markdown","metadata":{},"source":["We will be using 'AutoTokenizer' and 'AutoModelForSeq2SeqLM' from the 'transformers' library."]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-07-03T14:06:49.534989Z","iopub.status.busy":"2023-07-03T14:06:49.534116Z","iopub.status.idle":"2023-07-03T14:06:49.540393Z","shell.execute_reply":"2023-07-03T14:06:49.539373Z","shell.execute_reply.started":"2023-07-03T14:06:49.534945Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/arfsyed/Documents/Development/Hackathon/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["from transformers import AutoTokenizer, AutoModelForCausalLM"]},{"cell_type":"markdown","metadata":{},"source":["# Fetching the Model and Initializing a Tokenizer"]},{"cell_type":"markdown","metadata":{},"source":["We will be using \"facebook/blenderbot-400M-distill\" because it has an open-source license and runs relatively fast."]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-07-03T14:06:49.541912Z","iopub.status.busy":"2023-07-03T14:06:49.541492Z","iopub.status.idle":"2023-07-03T14:06:55.362807Z","shell.execute_reply":"2023-07-03T14:06:55.361512Z","shell.execute_reply.started":"2023-07-03T14:06:49.541878Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-09-29 10:23:55.065138: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","model_name = \"microsoft/DialoGPT-medium\"\n","model = AutoModelForCausalLM.from_pretrained(model_name)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-07-03T14:06:55.367529Z","iopub.status.busy":"2023-07-03T14:06:55.366657Z","iopub.status.idle":"2023-07-03T14:06:55.512474Z","shell.execute_reply":"2023-07-03T14:06:55.511009Z","shell.execute_reply.started":"2023-07-03T14:06:55.367480Z"},"trusted":true},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(model_name)"]},{"cell_type":"markdown","metadata":{},"source":["# Encoding Conversation History and Prompt from User"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-07-03T14:06:55.514448Z","iopub.status.busy":"2023-07-03T14:06:55.514073Z","iopub.status.idle":"2023-07-03T14:06:55.520887Z","shell.execute_reply":"2023-07-03T14:06:55.519133Z","shell.execute_reply.started":"2023-07-03T14:06:55.514417Z"},"trusted":true},"outputs":[],"source":["#Storing the Conversation History in a List\n","conversation_history = []"]},{"cell_type":"markdown","metadata":{},"source":["During each interaction, we will pass our conversation history to the model along with our input so that it may also reference the previous conversation when generating the next answer. The transformers library function we are using expects to receive the conversation history as a string, with each element separated by the newline character '\\n'. Thus, we create such a string. We'll use the join() method to do that. (Initially, our history_string will be an empty string and will grow as the conversation goes on)."]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-07-03T14:06:55.523859Z","iopub.status.busy":"2023-07-03T14:06:55.523441Z","iopub.status.idle":"2023-07-03T14:06:55.537644Z","shell.execute_reply":"2023-07-03T14:06:55.536246Z","shell.execute_reply.started":"2023-07-03T14:06:55.523825Z"},"trusted":true},"outputs":[],"source":["history_string = \"\\n\".join(conversation_history)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-07-03T14:06:55.540301Z","iopub.status.busy":"2023-07-03T14:06:55.539735Z","iopub.status.idle":"2023-07-03T14:06:55.552341Z","shell.execute_reply":"2023-07-03T14:06:55.550607Z","shell.execute_reply.started":"2023-07-03T14:06:55.540259Z"},"trusted":true},"outputs":[],"source":["#Using a simple input text to test\n","input_text = \"hello\""]},{"cell_type":"markdown","metadata":{},"source":["# Tokenization of User Prompt and Chat History"]},{"cell_type":"markdown","metadata":{},"source":["Tokenization converts user inputs/ prompt into a form, understandable by the model."]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-07-03T14:06:55.555104Z","iopub.status.busy":"2023-07-03T14:06:55.554703Z","iopub.status.idle":"2023-07-03T14:06:55.565944Z","shell.execute_reply":"2023-07-03T14:06:55.564960Z","shell.execute_reply.started":"2023-07-03T14:06:55.555064Z"},"trusted":true},"outputs":[],"source":["chat_history_ids = []\n","new_user_input_ids = []\n","inputs = tokenizer.encode(input_text + tokenizer.eos_token, return_tensors=\"pt\")\n","bot_input_ids = inputs"]},{"cell_type":"markdown","metadata":{},"source":["# Generate Ouput From The Model"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-07-03T14:06:55.568297Z","iopub.status.busy":"2023-07-03T14:06:55.567567Z","iopub.status.idle":"2023-07-03T14:07:02.540242Z","shell.execute_reply":"2023-07-03T14:07:02.539041Z","shell.execute_reply.started":"2023-07-03T14:06:55.568261Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]}],"source":["output = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)"]},{"cell_type":"markdown","metadata":{},"source":["# Decode Output"]},{"cell_type":"markdown","metadata":{},"source":["Detokenization is the process of combining or merging individual tokens back into their original form, typically to reconstruct the original text or sentence."]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-07-03T14:07:02.544975Z","iopub.status.busy":"2023-07-03T14:07:02.544135Z","iopub.status.idle":"2023-07-03T14:07:02.553198Z","shell.execute_reply":"2023-07-03T14:07:02.551979Z","shell.execute_reply.started":"2023-07-03T14:07:02.544927Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'helloHello! :D'"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["response = tokenizer.decode(output[0], skip_special_tokens=True).strip()\n","response"]},{"cell_type":"markdown","metadata":{},"source":["We've successfully had an interaction with our chatbot, we've given it a prompt, and we received its response. Next, we update our conversation history, so that we may pass it with the next iteration."]},{"cell_type":"markdown","metadata":{},"source":["# Update Conversation History"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-07-03T14:07:02.555810Z","iopub.status.busy":"2023-07-03T14:07:02.554816Z","iopub.status.idle":"2023-07-03T14:07:02.568070Z","shell.execute_reply":"2023-07-03T14:07:02.566625Z","shell.execute_reply.started":"2023-07-03T14:07:02.555763Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['hello', 'helloHello! :D']"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["conversation_history.append(input_text)\n","conversation_history.append(response)\n","conversation_history"]},{"cell_type":"markdown","metadata":{},"source":["# Conclusion"]},{"cell_type":"markdown","metadata":{},"source":["We have built a basic chatbot using Hugging Face lab by utilizing a pre-trained model called 'facebook/blenderbot-400M-distill'. To repeat the process and keep it going in a loop, you can use a while loop for that: \n","- while True:\n","    - #Create conversation history string\n","    - history_string = \"\\n\".join(conversation_history)\n","    - #Get the input data from the user\n","    - input_text = input(\"> \")\n","    - #Tokenize the input text and history\n","    - inputs = tokenizer.encode_plus(history_string, input_text, return_tensors=\"pt\")\n","    - #Generate the response from the model\n","    - outputs = model.generate(**inputs)\n","    - #Decode the response\n","    - response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n","    - #Add interaction to conversation history\n","    - conversation_history.append(input_text)\n","    - conversation_history.append(response)\n","\n","This ensures the process keeps getting repeated with each new prompt/ input. There are many other models out there to try based on the project and its requirements, this was a short tutorial to help gain some understanding of how chatbots work. Happy learning!"]},{"cell_type":"markdown","metadata":{},"source":["Test\n","- i = 0\n","- while i < 5:\n","    - #Create conversation history string\n","    - history_string = \"\\n\".join(conversation_history)\n","    - #Get the input data from the user\n","    - input_text = input(\"> \")\n","    - #Tokenize the input text and history\n","    - inputs = tokenizer.encode_plus(history_string, input_text, return_tensors=\"pt\")\n","    - #Generate the response from the model\n","    - output = model.generate(**inputs)\n","    - #Decode the response\n","    - response = tokenizer.decode(output[0], skip_special_tokens=True).strip()\n","    - #Add interaction to conversation history\n","    - print(\"Bot: \", response)\n","    - conversation_history.append(input_text)\n","    - conversation_history.append(response)\n","    - i+=1"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["from transformers import AutoModelForCausalLM, AutoTokenizer\n","import torch\n","\n","hf_name = \"microsoft/DialoGPT-medium\"\n","tokenizer = AutoTokenizer.from_pretrained(hf_name)\n","model = AutoModelForCausalLM.from_pretrained(hf_name)\n"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"name":"stdout","output_type":"stream","text":[">>User Input:  Hi there!\n",">>DialogPT: Hi! :D\n"]}],"source":["\n","# Let's chat for 5 lines\n","for step in range(1):\n","    # encode the new user input, add the eos_token and return a tensor in Pytorch\n","    user_input = input(\">> User:\")\n","    print(\">>User Input: \", user_input)\n","    new_user_input_ids = tokenizer.encode(user_input + tokenizer.eos_token, return_tensors='pt')\n","\n","    # append the new user input tokens to the chat history\n","    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n","\n","    # generated a response while limiting the total chat history to 1000 tokens, \n","    chat_history_ids = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n","\n","    # pretty print last ouput tokens from bot\n","    print(\">>DialogPT: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["from transformers import AutoModelForCausalLM, AutoTokenizer\n","import torch\n","\n","hf_name = \"togethercomputer/GPT-NeoXT-Chat-Base-20B\"\n","tokenizer = AutoTokenizer.from_pretrained(hf_name)\n","model = AutoModelForCausalLM.from_pretrained(hf_name)"]},{"cell_type":"markdown","metadata":{},"source":["\n","# Let's chat for 5 lines\n","for step in range(1):\n","    # encode the new user input, add the eos_token and return a tensor in Pytorch\n","    user_input = input(\">> User:\")\n","    print(\">>User Input: \", user_input)\n","    new_user_input_ids = tokenizer.encode(user_input + tokenizer.eos_token, return_tensors='pt')\n","\n","    # append the new user input tokens to the chat history\n","    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n","\n","    # generated a response while limiting the total chat history to 1000 tokens, \n","    chat_history_ids = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n","\n","    # pretty print last ouput tokens from bot\n","    print(\">>DialogPT: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":4}
